{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dc9eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import depth_transformations as dt\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from rich.traceback import install as install_rich\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import open3d as o3d\n",
    "install_rich()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6261942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b39468",
   "metadata": {},
   "source": [
    "#### Helpers and Plotters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f11384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_plot(im0, im1, label0=\"\", label1=\"\"):\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(label0)\n",
    "    plt.imshow(im0)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(label1)\n",
    "    plt.imshow(im1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab3d38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_values(a,name=\"\"):\n",
    "    if name: print(name)\n",
    "    print(f\"min: {a.min()}, mean: {a.mean()}, max: {a.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b414fa87",
   "metadata": {},
   "source": [
    "### Constants and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6036be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constnats and paths\n",
    "SCENE = 'intrinsic_tester_sphere'\n",
    "SPLIT = ''\n",
    "DATASET_PATH = \"/home/dtetruash/Thesis/datasets/nerf-blender/nerf_synthetic\"\n",
    "SCENE_PATH = f\"{DATASET_PATH}/{SCENE}\"\n",
    "DATA_PATH = f\"{SCENE_PATH}/{SPLIT}\" if SPLIT else SCENE_PATH\n",
    "\n",
    "LIGHTS_FILE = f\"{SCENE_PATH}/lights_{SCENE}.json\"\n",
    "TRANSFORMS_FILE = f\"{SCENE_PATH}/transforms_{SPLIT}.json\" if SPLIT else f\"{SCENE_PATH}/transforms.json\"\n",
    "\n",
    "IMAGE_NUMBER = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199181d2",
   "metadata": {},
   "source": [
    "###  Loading Images & Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6769d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Transforms\n",
    "with open(TRANSFORMS_FILE, 'r') as tf:\n",
    "    image_transforms = json.loads(tf.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76479859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the transform for the given image\n",
    "def get_c2w(image_number):\n",
    "    return np.array(image_transforms['frames'][image_number]['transform_matrix'])\n",
    "\n",
    "# Transfomation matrix functions\n",
    "def to_translation(c2w):\n",
    "    return c2w[:3, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff9fc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image loading functions\n",
    "def get_image_name(image_number, channel=\"\"):\n",
    "    return f\"{DATA_PATH}/r_{image_number:03d}{f'_{channel}' if channel else ''}.png\"\n",
    "\n",
    "def get_image(image_number, channels=[], open_func=Image.open):\n",
    "    \"\"\"Get an image along with it's given channels.\"\"\"\n",
    "    images = {'combined': get_image_name(image_number)}\n",
    "    images.update({channel: get_image_name(image_number, channel) for channel in channels})\n",
    "    return {k: open_func(v) for (k, v) in images.items()}\n",
    "\n",
    "\n",
    "def remap_depth_black2white(depth_array):\n",
    "    \"\"\"Remap an 8-bit depth image where 255 -> near and 0 -> far\n",
    "    to the convention that 0 -> near and 255 -> far.\n",
    "    \"\"\"\n",
    "    return -depth_array + 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda963ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get needed image passes\n",
    "images = get_image(IMAGE_NUMBER, ['albedo', 'depth', 'normal', 'diffuse'])\n",
    "\n",
    "# Reloading to meet the RGBd creation function requirements on image channels\n",
    "image_combined_rgb = o3d.geometry.Image(np.asarray(images['combined'].convert(\"RGB\")))\n",
    "\n",
    "# invert the depth image\n",
    "depth_raw = remap_depth_black2white(np.asarray(images['depth'])[:, :, -1].astype(np.uint8))\n",
    "image_depth = o3d.geometry.Image(depth_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e734d78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images['normal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4ef2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loaded RAW images.\")\n",
    "two_plot(\n",
    "    np.asarray(images['combined']),\n",
    "    np.asarray(images['depth']),\n",
    "    label0=\"combined image\",\n",
    "    label1=\"depth image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d553f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Images with correct channels\")\n",
    "two_plot(image_combined_rgb, image_depth, label0=\"combined RGB image\", label1=\"scalar depth image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7f0e48",
   "metadata": {},
   "source": [
    "### Lights and Light Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545617f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get lights information\n",
    "with open(LIGHTS_FILE, 'r') as lf:\n",
    "    lights_info = json.loads(lf.read())\n",
    "f\"Number of lights {len(lights_info['lights'])}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2066eee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the location of the lights\n",
    "light_transforms = [np.array(light['transformation_matrix']) for light in lights_info['lights']]\n",
    "light_locations = [to_translation(transform) for transform in light_transforms]\n",
    "light_locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912e25c5",
   "metadata": {},
   "source": [
    "### Camera Parameters and Rays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0976eba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pinhole camera functions\n",
    "image_combined_array = np.asarray(images['combined'])\n",
    "H, W = image_combined_array.shape[:-1]\n",
    "# H = W = 100\n",
    "\n",
    "def get_focal(width, camera_angle_x):\n",
    "    return .5 * width / np.tan(.5 * camera_angle_x)\n",
    "\n",
    "def get_rays(H, W, focal, c2w):\n",
    "    \"\"\"Get ray origins, directions from a pinhole camera.\n",
    "    Taken from https://github.com/bmild/nerf/blob/master/run_nerf_helpers.py#L133C1-L140C26\"\"\"\n",
    "    i, j = np.meshgrid(np.arange(W, dtype=np.float32),\n",
    "                       np.arange(H, dtype=np.float32), indexing='xy')\n",
    "    dirs = np.stack([(i-W*.5)/focal, -(j-H*.5)/focal, -np.ones_like(i)], -1)\n",
    "    rays_d = np.sum(dirs[..., np.newaxis, :] * c2w[:3, :3], -1)\n",
    "    rays_o = np.broadcast_to(c2w[:3, -1], np.shape(rays_d))\n",
    "    return rays_o, rays_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2fe980",
   "metadata": {},
   "outputs": [],
   "source": [
    "focal = get_focal(W, image_transforms[\"camera_angle_x\"])\n",
    "focal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f86282",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2w = get_c2w(IMAGE_NUMBER)\n",
    "c2w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c328e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_o, rays_d = get_rays(H, W, focal, c2w)\n",
    "rays_d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18fd164",
   "metadata": {},
   "source": [
    "## Creating Point Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42535663",
   "metadata": {},
   "source": [
    "### Using Depth Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590251cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize_depth(depth_image_array, from_min=0, from_max=8):\n",
    "    \"\"\"Inverse the depth image mapping which we did in blender during compositing.\n",
    "    The default forrward mapping is (0,8) -> (1,0).\n",
    "    Return depth of each pixel in \"\"\"\n",
    "    depth_from_alpha = depth_image_array[..., -1]\n",
    "    return (depth_from_alpha/255. - 1) * -(from_max - from_min), depth_from_alpha > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1b367c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script echo skipping\n",
    "depth_vals, depth_mask = denormalize_depth(np.asarray(images['depth']))\n",
    "num_points = depth_mask.sum()\n",
    "print(f\"There are {num_points} points with finite depth in the image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4603a4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "two_plot(\n",
    "    depth_vals/8,\n",
    "    depth_mask,\n",
    "    label0=\"depth mapped\",\n",
    "    label1=\"depth mask\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010e2c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "# Compute point cloud!\n",
    "# 1. Compute the distances along the rays from camera to the z-depth values\n",
    "# Project the vector direction onto the world-space optical axis\n",
    "# scale the direciton vector by the depth/projection factor\n",
    "\n",
    "optical_axis = np.array([0,0,-1])\n",
    "world_optical_axis = c2w[:3, :3] @ optical_axis\n",
    "optical_axis, world_optical_axis, np.linalg.norm(world_optical_axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2382faba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "# Project the rays onto the optical axis. If rays lie on z=1,\n",
    "# then all projections should be equal  to 1\n",
    "f_factors =  rays_d[...,None,:] @ np.broadcast_to(world_optical_axis, rays_d.shape)[...,None]\n",
    "np.all(np.abs((f_factors[...,0,0] - 1 )) < 1e-6) # All f-factors are equal to 1 upto precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8029640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "# if the factor is 1, then all we must do is scale all directions by their depth value in those locations where there is depth\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.set_xlim3d(1, 3)\n",
    "ax.set_ylim3d(2, 4)\n",
    "ax.set_zlim3d(-2.5, -0.5)\n",
    "\n",
    "data = depth_vals[depth_mask, np.newaxis] * rays_d[depth_mask]\n",
    "\n",
    "ax.scatter([0], [0], [0], c='red') # Camera point\n",
    "ax.scatter(data[:,0], data[:,1], data[:,2],c=-depth_vals[depth_mask], cmap=plt.gray(), marker=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81c38f7",
   "metadata": {},
   "source": [
    "### Using Open3D RGBD + Point Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046646fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#o3d.geometry.RGBDImage.create_from_color_and_depth?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1a96c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "    image_combined_rgb, image_depth,\n",
    "    depth_scale=1/8, depth_trunc=8,\n",
    "    convert_rgb_to_intensity=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e50a2ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "two_plot(\n",
    "    rgbd_image.color,\n",
    "    rgbd_image.depth,\n",
    "    label0='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e42198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set intrinsic matrix\n",
    "f_x = f_y = focal\n",
    "# f_y = 1666.6666\n",
    "intrinsics = o3d.camera.PinholeCameraIntrinsic(W, H, f_x, f_y, W/2., H/2.)\n",
    "print(\"K = \")\n",
    "print(intrinsics.intrinsic_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59f546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = R.from_euler('x', 90, degrees=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e431ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = o3d.geometry.PointCloud.create_from_rgbd_image(\n",
    "    rgbd_image,\n",
    "    o3d.camera.PinholeCameraIntrinsic(intrinsics)\n",
    ")\n",
    "# Flip it, otherwise the pointcloud will be upside down\n",
    "pcd.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "# pcd.rotate(r.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaba49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.asarray(pcd.points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e60ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points == points.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd42071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script echo skipping\n",
    "o3d.visualization.draw_geometries([pcd], mesh_show_back_face=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f232c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "ax.set_aspect('equal', 'box')\n",
    "ax.set_title(\"Open3D Point Cloud (Unposed)\")\n",
    "# ax.scatter([0], [0], [0], c='red') # Camera point\n",
    "ax.scatter(points[:, 0], points[:, 1], points[:, 2], c=-depth_vals[depth_mask], cmap=plt.gray(), marker=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d16bfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pose the point cloud with the camera transform\n",
    "pcd.transform(c2w)\n",
    "points_posed = np.asarray(pcd.points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d19960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "ax.set_aspect('equal', 'box')\n",
    "ax.set_title(\"Open3D Point Cloud (Posed)\")\n",
    "ax.set_xlim(-1,1)\n",
    "ax.set_ylim(-1,1)\n",
    "ax.set_zlim(0,2)\n",
    "# ax.scatter([0], [0], [0], c='red') # Camera point\n",
    "ax.scatter(light_locations[0][0], light_locations[0][1], light_locations[0][2], c='red')\n",
    "ax.scatter(points_posed[:, 0], points_posed[:, 1], points_posed[:, 2], c=-depth_vals[depth_mask], cmap=plt.gray(), marker=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa83f11",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### Using Partha's Projection Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce52765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# 1. Get the camera matrices for each image.\n",
    "#    a. Use the transform provided. (It is just the extrinsics, in the blender convention)\n",
    "# use the intrinsics found earlier (f_y=f_x=1111px, 400,400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe99126",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "print(\"K = \")\n",
    "print(intrinsics.intrinsic_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c96084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_partha = dt.depth2pcd_posed(\n",
    "    np.asarray(rgbd_image.depth),\n",
    "    np.asarray(rgbd_image.color),\n",
    "    intrinsics.intrinsic_matrix,\n",
    "    c2w)\n",
    "\n",
    "# Flip it, otherwise the pointcloud will be upside down\n",
    "pcd.transform([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22c770b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = R.from_euler('x', 90, degrees=True)\n",
    "# pcd_partha.rotate(r.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea295be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "o3d.visualization.draw_geometries([pcd_partha], mesh_show_back_face=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b51a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "pcd_partha_array = np.asarray(pcd_partha.points)\n",
    "\n",
    "ax.set_aspect('equal', 'box')\n",
    "ax.scatter([0], [0], [0], c='red')  # Camera point\n",
    "ax.scatter(pcd_partha_array[:, 0], pcd_partha_array[:, 1], pcd_partha_array[:, 2], cmap=plt.gray(), marker=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f33d3a4",
   "metadata": {},
   "source": [
    "## Raster Rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff9ee6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the OLAT samples for the scene\n",
    "\n",
    "# Constants and containers for later\n",
    "POINT_SOURCE_POWER = 30\n",
    "\n",
    "raster_image = np.zeros((W, H, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd31afd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check the rotation matrix\n",
    "R = c2w[:3,:3]\n",
    "print(f\"det(R) = {np.linalg.det(R)}\")\n",
    "print(\"R^T @ R =\")\n",
    "print(R.T @ R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fa7a59",
   "metadata": {},
   "source": [
    "### Load camera-space normals and scale them to the correct ranges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c397e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_normals_pixels = (np.asarray(images['normal'])[:, :, :-1] / 255)\n",
    "for i in range(camera_normals_pixels.shape[-1]):\n",
    "    check_values(camera_normals_pixels[depth_mask][...,i], name=f\"Camera-space Normals {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a375373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translation and scaling needed to remap to [-1,1], [-1,1], and [-1,0] resp.\n",
    "normals_shift = np.array([-0.5]*3)\n",
    "normals_scale = np.array([2.0]*3)\n",
    "#normals_scale[-1] *= -1\n",
    "normals_shift, normals_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed46abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_normals = (camera_normals_pixels + normals_shift) * normals_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4951dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(camera_normals.shape[-1]):\n",
    "    check_values(camera_normals[depth_mask][...,i], name=f\"Camera-space Normals {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb902c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the norms of the normals\n",
    "camera_normals_norms = np.linalg.norm(camera_normals, axis=2)\n",
    "camera_normals_norms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1af794",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_values(camera_normals_norms[depth_mask], name=\"Camera Normals Norms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd5b7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the normals\n",
    "camera_normals_normalized = camera_normals / camera_normals_norms[...,np.newaxis] * depth_mask[...,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9912d2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_values(np.linalg.norm(camera_normals_normalized[depth_mask], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10c55b7",
   "metadata": {},
   "source": [
    "#### Get World Normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d21d8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the vectors to be a list of 3D points\n",
    "camera_normals_flattened = camera_normals_normalized.reshape(-1, 3).T\n",
    "camera_normals_flattened.shape  # Column vectors per image pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8762eb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the vectors to world space\n",
    "world_normals_flattened = np.dot(R, camera_normals_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc03d67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the transformed vectors back to the original image shape\n",
    "world_normals = world_normals_flattened.T.reshape(camera_normals.shape)\n",
    "world_normals.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13722f07",
   "metadata": {},
   "source": [
    "### Validate by adding normals to point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a503cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd.normals = o3d.utility.Vector3dVector(world_normals[depth_mask])\n",
    "pcd.normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a464b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27d9b6e",
   "metadata": {},
   "source": [
    "#### Get Light Distances for First Light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac91e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "light_vectors = np.zeros_like(raster_image)\n",
    "light_vectors[depth_mask] = points_posed - light_locations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b1e19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get norms of the light vectors\n",
    "light_norms = np.zeros(raster_image.shape[:-1])\n",
    "light_norms[depth_mask] = np.linalg.norm(light_vectors[depth_mask], axis=1)\n",
    "light_norms_sqr = np.square(light_norms)\n",
    "light_norms.shape, light_norms_sqr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370b3661",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(light_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ce1272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized light vectors\n",
    "light_vectors[depth_mask] = light_vectors[depth_mask] / light_norms[depth_mask][...,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ca4d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute dots\n",
    "normal_dot_light = np.zeros(raster_image.shape[:-1])\n",
    "normal_dot_light = np.sum(-world_normals.reshape((-1, 3)) * light_vectors.reshape((-1, 3)), axis=1)\n",
    "\n",
    "normal_dot_light = np.maximum(normal_dot_light.reshape((W, H)), 0) * depth_mask\n",
    "plt.imshow(normal_dot_light, cmap=plt.gray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51ddee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute reaster image\n",
    "albedo = np.asarray(images['albedo'])[:, :, :3].astype(np.float32) / 255.\n",
    "normal_dot_light = normal_dot_light / normal_dot_light.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c7eb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_image = albedo * normal_dot_light[:, :, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d28b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(normal_dot_light / (light_norms_sqr + 1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc770c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_values(raster_image)\n",
    "check_values(albedo)\n",
    "check_values(normal_dot_light)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e0ad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_values(raster_image, name='Raster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e3237e",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_plot(raster_image, albedo, label0=\"raster\", label1=\"albedo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962745a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_image_vis = raster_image.copy()\n",
    "raster_image_vis[~depth_mask] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679aa9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_plot(raster_image_vis, np.asarray(images['diffuse']), label0=\"raster\", label1=\"diffuse GT (with denoising)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0f0620",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imsave('raster.png', raster_image_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fec479f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
